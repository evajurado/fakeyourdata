{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "682ee8ed",
   "metadata": {},
   "source": [
    "## Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ce721f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "learning_rate = 0.0005\n",
    "noise_dim = 32 # dimension of random noise as generator's input\n",
    "layers_dim = 128 # dimension at layers inside NN\n",
    "epochs = 100000+1\n",
    "model_name = 'model'\n",
    "noise_dim = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa427878",
   "metadata": {},
   "source": [
    "## Install libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604fe851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.datasets as ds\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, ReLU, LeakyReLU\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import keras\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import wasserstein_distance\n",
    "from table_evaluator import load_data, TableEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49907600",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2009ade2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "\n",
    "dfdiabetes_x = pd.DataFrame(ds.load_diabetes().data)\n",
    "dfdiabetes_x.columns = ds.load_diabetes().feature_names\n",
    "dfdiabetes_y = pd.DataFrame(ds.load_diabetes().target)\n",
    "dfdiabetes_y.columns = ['Outcome']\n",
    "df = pd.concat([dfdiabetes_x,dfdiabetes_y], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db05e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976aad28",
   "metadata": {},
   "source": [
    "## GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae55f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    \n",
    "    def __init__(self, batch_size, learning_rate, noise_dim, data_dim, layers_dim):\n",
    "        # Initialize input values\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.noise_dim = noise_dim\n",
    "        self.data_dim = data_dim\n",
    "        self.layers_dim = layers_dim\n",
    "        \n",
    "        def create_generator(batch_size, input_shape, layers_dim, data_dim):\n",
    "            input = Input(shape=input_shape, batch_size=batch_size)\n",
    "            x = Dense(layers_dim)(input)\n",
    "            x = ReLU()(x)\n",
    "            x = Dense(layers_dim * 2)(x)\n",
    "            x = ReLU()(x)\n",
    "            x = Dense(layers_dim * 4)(x)\n",
    "            x = ReLU()(x)\n",
    "            x = Dense(data_dim)(x)\n",
    "            return Model(inputs=input, outputs=x)\n",
    "    \n",
    "        def create_discriminator(batch_size, input_shape, layers_dim):\n",
    "            input = Input(shape=input_shape, batch_size=batch_size)\n",
    "            x = Dense(layers_dim * 4)(input)\n",
    "            x = LeakyReLU()(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(layers_dim * 2)(x)\n",
    "            x = LeakyReLU()(x)\n",
    "            x = Dropout(0.1)(x)\n",
    "            x = Dense(layers_dim)(x)\n",
    "            x = LeakyReLU()(x)\n",
    "            x = Dense(1, activation='sigmoid')(x)\n",
    "            return Model(inputs=input, outputs=x)\n",
    "        \n",
    "        self.generator = create_generator(self.batch_size, (self.noise_dim,), self.layers_dim, self.data_dim)\n",
    "        self.discriminator = create_discriminator(self.batch_size, (self.data_dim,), self.layers_dim)\n",
    "        \n",
    "        # Adam optimizer\n",
    "        opt = Adam(self.learning_rate)\n",
    "        # Discriminator is a binary classification real/fake -> loss is binary crossentropy and metric accuracy\n",
    "        self.discriminator.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])        \n",
    "        \n",
    "        # STRUCTURE\n",
    "        def create_gan(self):\n",
    "            # For the combined model, only train the generator\n",
    "            self.discriminator.trainable = False\n",
    "            \n",
    "            gen_input = Input(shape=(self.noise_dim,)) # The generator takes noise as input\n",
    "            gen_output = self.generator(gen_input)\n",
    "            \n",
    "            disc_output = self.discriminator(gen_output) # The discriminator takes generated images as input \n",
    "            \n",
    "            # GAN model: generator + discriminator\n",
    "            gan = Model(gen_input, disc_output)\n",
    "            gan.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "            \n",
    "            return gan\n",
    "        \n",
    "        self.gan = create_gan(self)\n",
    "\n",
    "    def train(self, data, epochs, model_name):        \n",
    "        ones = np.ones((self.batch_size, 1))\n",
    "        zeros = np.zeros((self.batch_size, 1))\n",
    "\n",
    "        for epoch in range(epochs):    \n",
    "            # First input: to the generator \n",
    "            noise = tensorflow.random.normal((self.batch_size, self.noise_dim)) #batch_size x noise_dim \n",
    "            # Generator - Noise inputs the generator \n",
    "            gen_data = self.generator.predict(noise)\n",
    "            # Second input: to the discriminator from real data\n",
    "            real_data = data.sample(n = batch_size).to_numpy()\n",
    "             \n",
    "            # Train the discriminator on both paths: from real data and from generated data\n",
    "            # When data is real, it outputs 1; when data is generated, it outputs 0\n",
    "            dloss_real = self.discriminator.train_on_batch(real_data, ones)\n",
    "            dloss_gen = self.discriminator.train_on_batch(gen_data, zeros)\n",
    "            d_loss = np.add(dloss_real, dloss_gen)/2\n",
    "    \n",
    "            # Train the generator to fool the discriminator\n",
    "            # When data comes from noise and is generated, it outputs 1\n",
    "            noise = tensorflow.random.normal((self.batch_size, self.noise_dim))\n",
    "            g_loss = self.gan.train_on_batch(noise, ones)\n",
    "    \n",
    "            # Save losses from generator and discriminator\n",
    "            genlosses.append(g_loss)\n",
    "            disclosses.append(d_loss[0])\n",
    "            \n",
    "            # Plot the progress every 10 epochs\n",
    "            if epoch % 10 == 0:\n",
    "                print(\"Epoch %d with discriminator loss %f and generator loss %f (x100)\" % (epoch, d_loss[0]*100, g_loss*100))\n",
    "                        \n",
    "            # Save model every 100 epochs\n",
    "            if epoch % 100 == 0:\n",
    "                self.generator.save_weights(model_name + '/gen_weights_' + str(epoch) + '.h5')\n",
    "                self.discriminator.save_weights(model_name + '/disc_weights_' + str(epoch) + '.h5')\n",
    "            noise = tensorflow.random.normal((123, self.noise_dim))\n",
    "            gen_data = self.generator(noise)\n",
    "    \n",
    "    # Save generator weights\n",
    "    def save(self, path):\n",
    "        self.generator.save_weights(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79e93a8",
   "metadata": {},
   "source": [
    "## GAN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2bf7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "genlosses = []\n",
    "disclosses = []\n",
    "data_dim = df.shape[1]\n",
    "\n",
    "if not os.path.exists(model_name):\n",
    "    os.mkdir(model_name)\n",
    "\n",
    "model = GAN(batch_size, learning_rate, noise_dim, data_dim, layers_dim)\n",
    "model.train(df, epochs, model_name)\n",
    "model.save(model_name + '/gan/saved/generator')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945d1a93",
   "metadata": {},
   "source": [
    "## Training output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f1b625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "pd.DataFrame(genlosses).plot(ax=ax, title='Loss Functions')\n",
    "pd.DataFrame(disclosses).plot(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510c394f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator schema\n",
    "\n",
    "model.generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4263b109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator schema\n",
    "\n",
    "model.discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9f51d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN schema\n",
    "\n",
    "model.gan.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05daa860",
   "metadata": {},
   "source": [
    "## Tabular data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91df6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = len(df) # number of generated cases\n",
    "noise = np.random.normal(size=(test_size, noise_dim))\n",
    "generator_model = model.generator\n",
    "generator_model.load_weights(model_name+'/gen_weights_'+str(epochs-1)+'.h5')\n",
    "\n",
    "g_z = generator_model.predict(noise)\n",
    "dfgen = pd.DataFrame(g_z, columns=df.columns)\n",
    "dfgen.to_csv(model_name+'/Generated_data.csv')\n",
    "\n",
    "dfgen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56241a5",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1ddd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wasserstein distance\n",
    "\n",
    "wd = []\n",
    "for c in df.columns:\n",
    "    wdistance = wasserstein_distance(df[c], dfgen[c])\n",
    "    wd.append(wdistance)\n",
    "\n",
    "distances = pd.DataFrame(np.array(wd), np.array(df.columns), columns = ['Distance'])\n",
    "distances = distances.reset_index()\n",
    "distances.columns = ['Variable', 'Distance']\n",
    "\n",
    "print(distances) \n",
    "print('\\nMean Wasserstein Distance:', np.mean(wd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe8bec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual metrics\n",
    "\n",
    "table_evaluator = TableEvaluator(df, dfgen)\n",
    "table_evaluator.visual_evaluation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a29821",
   "metadata": {},
   "source": [
    "## Save unstandarized generated dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5557ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfgen_inv = pd.DataFrame(scaler.inverse_transform(dfgen), columns=dfgen.columns)\n",
    "dfgen_inv.to_csv(model_name+'/Unstandarized_Generated_data.csv')\n",
    "\n",
    "dfgen_inv.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
